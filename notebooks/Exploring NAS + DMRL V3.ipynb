{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring results for NAS with DMRL [V2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for interactive notebook (see:\n",
    "# https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html)\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout\n",
    "\n",
    "# Import to list files in directories\n",
    "import glob\n",
    "\n",
    "# Import for regular expressions\n",
    "import re\n",
    "\n",
    "# Imports for path operations\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# For date operations\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"/Users/gomerudo/workspace/thesis_results\"\n",
    "\n",
    "def rettext(text):\n",
    "    return text\n",
    "\n",
    "def search_in_file(file, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    results = []\n",
    "    for i, line in enumerate(open(file)):\n",
    "        for match in re.finditer(pattern, line):\n",
    "            results.append(match.groups())\n",
    "    return results\n",
    "\n",
    "form_item_layout = Layout(\n",
    "    width=\"50%\"\n",
    ")\n",
    "\n",
    "w_resdirs = interactive(\n",
    "    rettext,\n",
    "    text=sorted(glob.glob(\"{dir}/[0-9]*\".format(dir=RESULTS_DIR))),\n",
    "    layout=form_item_layout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9b685005ba4ad0b0abd8805f27ece9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='text', options=('/Users/gomerudo/workspace/thesis_results/26374', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(w_resdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Note**: In order to get the results, run all cells below once you have selected the desired directory in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and parsing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "############ OBTAIN THE FILES AND DIRECTORIES TO QUERY FOR ANALYSIS ############\n",
    "################################################################################\n",
    "\n",
    "# Obtain the chosen directory\n",
    "chosen_dir = w_resdirs.result\n",
    "\n",
    "# experiments dir\n",
    "exp_dir = glob.glob(\"{dir}/experiment*[!.zip]\".format(dir=chosen_dir))[0]\n",
    "\n",
    "# This is a list of all openai dirs, sorted by name (hence, by timestamp)\n",
    "openai_dirs = sorted(glob.glob(\"{dir}/openai*[!.zip]\".format(dir=exp_dir)))\n",
    "if not len(openai_dirs):\n",
    "    openai_dirs = sorted(glob.glob(\"{dir}/opeanai*[!.zip]\".format(dir=exp_dir)))\n",
    "\n",
    "# A simple DB of experiments and actions_info.csv should be there\n",
    "dbexp_file = glob.glob(\"{dir}/db*\".format(dir=exp_dir))[0]\n",
    "ainfo_file = glob.glob(\"{dir}/act*\".format(dir=exp_dir))[0]\n",
    "#episode_logs = glob.glob(\"{dir}/episode_logs/*\".format(dir=openai_dir))\n",
    "\n",
    "flog_file = glob.glob(\"{dir}/sl*\".format(dir=chosen_dir))[0]\n",
    "\n",
    "# Make dataframes for the db of experiments and the actions summary\n",
    "dbexp_df = pd.read_csv(dbexp_file)\n",
    "ainfo_df = pd.read_csv(ainfo_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "########### BUILD THE RELEVANT DATA FRAMES TO PRINT FOR MAIN SUMMARY ###########\n",
    "################################################################################\n",
    "    \n",
    "# Try to obtain the current times\n",
    "running_times = search_in_file(flog_file, \".*\\s+(.*)elapsed\")\n",
    "if len(running_times) == len(openai_dirs):\n",
    "    f_running_times = []\n",
    "    for time in running_times:\n",
    "        time_cleansed = time[0].split(\".\")[0]\n",
    "        f_running_times.append(time_cleansed)\n",
    "else:\n",
    "    prev_timestamp = 0\n",
    "    f_running_times = []\n",
    "    for directory in openai_dirs:\n",
    "        exp_dirname_only = os.path.basename(directory)\n",
    "        timestamp = os.path.basename(exp_dirname_only.split(\"-\")[1])\n",
    "        d2 = datetime.strptime(timestamp, \"%Y%m%d%H%M%S\")\n",
    "        if prev_timestamp:  # 2019 05 29 211533\n",
    "            d1 = datetime.strptime(prev_timestamp, \"%Y%m%d%H%M%S\")\n",
    "            f_running_times.append(str(d2 - d1))\n",
    "        prev_timestamp = timestamp\n",
    "    f_running_times.append(\"NA\")\n",
    "    \n",
    "openai_dirs_df = pd.DataFrame(zip(openai_dirs, f_running_times), columns=[\"Log directory\", \"Runtime\"])\n",
    "\n",
    "# 4. Search all exceptions\n",
    "exceptions_all = search_in_file(flog_file, \"failed with exception of type.*<(.*)>.*Message.*:\\s*(.*)\")\n",
    "n_exceptions = len(exceptions_all)\n",
    "\n",
    "exceptions_set = set()\n",
    "for error, message in exceptions_all:\n",
    "    exceptions_set.add(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "ainfo_df.shape[0]": "9",
     "chosen_dir": "/Users/gomerudo/workspace/thesis_results/26374",
     "dbexp_df.shape[0]": "708",
     "flog_file": "/Users/gomerudo/workspace/thesis_results/26374/slurm-26374.out",
     "n_exceptions": "4",
     "openai_dirs_df": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Log directory</th>\n      <th>Runtime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/Users/gomerudo/workspace/thesis_results/26374/experiment-20190624124652/openai-20190624124653</td>\n      <td>13:08:50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "#### Highglights\n",
    "\n",
    "- **Chosen results directory is:** {{chosen_dir}}\n",
    "- **Full log is available at:** {{flog_file}}\n",
    "- **Total number of experiments in DB:** {{dbexp_df.shape[0]}}\n",
    "- **Total number of actions considered:** {{ainfo_df.shape[0]}}\n",
    "- **Total number of exceptions:** {{n_exceptions}}\n",
    "\n",
    "#### Individual run directories/time\n",
    "\n",
    "{{openai_dirs_df}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "pd.DataFrame(exceptions_set, columns = [\"Error type\"])": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Error type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>class 'ValueError'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "### Errors found in log while building networks\n",
    "\n",
    "{{pd.DataFrame(exceptions_set, columns = [\"Error type\"])}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_architectures(trial_log):\n",
    "    ep_df = pd.read_csv(trial_log)\n",
    "    \n",
    "    # 1. Get the best architecture\n",
    "    # 2. \n",
    "    \n",
    "    \n",
    "for i, openai_dir in enumerate(openai_dirs):\n",
    "    episode_logs = sorted(glob.glob(\"{dir}/episode_logs/*\".format(dir=openai_dir)))\n",
    "    actions_log, max_step_count_history, best_reward_history, all_rewards_history = analyze_trial(episode_logs, i+1)\n",
    "    stats.append(\n",
    "        {\n",
    "            'actions_log': actions_log,\n",
    "            'max_step_history': max_step_count_history,\n",
    "            'best_reward_history': best_reward_history,\n",
    "            'all_rewards_history': all_rewards_history\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "len(openai_dirs)": "1"
    }
   },
   "source": [
    "#### Summary of trials\n",
    "\n",
    "- **Total number of trials:** {{len(openai_dirs)}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "len(openai_dirs)": "42"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def analyze_trial(trial_logs, trial_n):\n",
    "    # We'll use this for the distribution of actions per trial\n",
    "    actions_log = [0]*ainfo_df.shape[0]\n",
    "\n",
    "    # This will store the max_step achieved per episode.\n",
    "    max_step_count_history = []\n",
    "    best_reward_history = []\n",
    "    all_rewards_history = []\n",
    "    step_in_ep = 0\n",
    "    reward_in_ep = 0\n",
    "    for log_file in trial_logs:\n",
    "        try:\n",
    "            ep_df = pd.read_csv(\"{f}\".format(f=log_file))\n",
    "\n",
    "            for idx, row in ep_df.iterrows():\n",
    "                # 1. Add information to the distribution of actions\n",
    "                action_id = int(row['action_id'])\n",
    "                actions_log[action_id] += 1\n",
    "\n",
    "                # 2. Keep the rewards\n",
    "                c_reward = int(row['reward'])\n",
    "                all_rewards_history.append(c_reward)\n",
    "                \n",
    "                # 3. Keep the best information and count episodes\n",
    "                c_sc = int(row['step_count'])\n",
    "                \n",
    "                # 4. If we keep counting steps, accumulate information\n",
    "                if c_sc > step_in_ep:\n",
    "                    step_in_ep = c_sc\n",
    "                    reward_in_ep = c_reward if c_reward > reward_in_ep else reward_in_ep\n",
    "                # Otherwise, append the best information we read\n",
    "                else:\n",
    "                    max_step_count_history.append(step_in_ep)\n",
    "                    best_reward_history.append(reward_in_ep)\n",
    "                    step_in_ep = c_sc\n",
    "                    reward_in_ep = 0\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "\n",
    "    return actions_log, max_step_count_history, best_reward_history, all_rewards_history\n",
    "\n",
    "\n",
    "stats = []\n",
    "for i, openai_dir in enumerate(openai_dirs):\n",
    "    episode_logs = sorted(glob.glob(\"{dir}/episode_logs/*\".format(dir=openai_dir)))\n",
    "    actions_log, max_step_count_history, best_reward_history, all_rewards_history = analyze_trial(episode_logs, i+1)\n",
    "    stats.append(\n",
    "        {\n",
    "            'actions_log': actions_log,\n",
    "            'max_step_history': max_step_count_history,\n",
    "            'best_reward_history': best_reward_history,\n",
    "            'all_rewards_history': all_rewards_history\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9f32b47fe844b89bba78d17daadaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='trial', options=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def trial_plots(trial=list(range(1, len(stats) + 1))):\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = 2, ncols=2)\n",
    "    plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.8)\n",
    "    \n",
    "    fig.set_size_inches(16, 6)\n",
    "    fig.suptitle(\n",
    "        \"Results for trial {t}\\nNumber of episodes: {e}\".format(\n",
    "            t=trial,\n",
    "            e=len(stats[trial-1]['best_reward_history'])\n",
    "        ),\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "    # Plot the actions distribution\n",
    "    dact_ax = axes[0][0]\n",
    "    dact_ax.set_title(\"Distribution of actions taken during trial\")\n",
    "    dact_ax.set_xlabel(\"Action ID\")\n",
    "    dact_ax.set_ylabel(\"Count\")\n",
    "\n",
    "    dact_ax.bar(\n",
    "        range(len(stats[trial-1]['actions_log'])),\n",
    "        stats[trial-1]['actions_log']\n",
    "    )\n",
    "    \n",
    "    # Plot the max_step evolution\n",
    "    maxsteps_ax = axes[0][1]\n",
    "    maxsteps_ax.set_title(\"Evolution of max_step achieved through episodes\")\n",
    "    maxsteps_ax.set_xlabel(\"Episode\")\n",
    "    maxsteps_ax.set_ylabel(\"Max Step achieved\")\n",
    "    maxsteps_ax.plot(\n",
    "        range(len(stats[trial-1]['max_step_history'])),\n",
    "        stats[trial-1]['max_step_history']\n",
    "    )\n",
    "\n",
    "    # Plot the best reward evolution\n",
    "    bestrew_ax = axes[1][0]\n",
    "    bestrew_ax.set_title(\"Evolution of best reward through episodes\")\n",
    "    bestrew_ax.set_xlabel(\"Episode\")\n",
    "    bestrew_ax.set_ylabel(\"Reward\")\n",
    "    bestrew_ax.plot(\n",
    "        range(len(stats[trial-1]['best_reward_history'])),\n",
    "        stats[trial-1]['best_reward_history']\n",
    "    )\n",
    "\n",
    "    # Plot the histogram of rewards\n",
    "    bestrew_ax = axes[1][1]\n",
    "    bestrew_ax.set_title(\"Distribution of obtained rewards during trial\")\n",
    "    bestrew_ax.set_xlabel(\"Episode\")\n",
    "    bestrew_ax.set_ylabel(\"Count\")\n",
    "    bestrew_ax.hist(\n",
    "        stats[trial-1]['all_rewards_history']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
