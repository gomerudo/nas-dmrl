{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:28:59.738035Z",
     "start_time": "2019-09-25T21:28:58.115579Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import math\n",
    "import multiprocessing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Meta-dataset's TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:28:59.787398Z",
     "start_time": "2019-09-25T21:28:59.740695Z"
    }
   },
   "outputs": [],
   "source": [
    "RECORDS_DIR = \"/Users/gomerudo/workspace/thesis_results/dtd\"\n",
    "pattern = \"{dir}/*.tfrecords\".format(dir=RECORDS_DIR)\n",
    "tfrecords_list = sorted(glob.glob(pattern))\n",
    "tfrecord_data = tf.data.TFRecordDataset(tfrecords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T22:06:41.845784Z",
     "start_time": "2019-09-25T22:06:41.416056Z"
    }
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    'image': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'label': tf.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "c = 0\n",
    "for record in tfrecord_data:\n",
    "    if c > 5:\n",
    "        break\n",
    "    parsed = tf.parse_single_example(record, features)\n",
    "\n",
    "    # The image (features)\n",
    "    image_decoded = tf.image.decode_jpeg(parsed['image'], channels=3)\n",
    "    img = Image.fromarray(image_decoded.numpy(), 'RGB')\n",
    "    img.show(title=\"algo\")\n",
    "    c+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T22:03:34.700005Z",
     "start_time": "2019-09-25T22:03:09.759434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch #1\n",
      "Processing batch #2\n",
      "Processing batch #3\n",
      "Processing batch #4\n",
      "Processing batch #5\n",
      "Processing batch #6\n",
      "Processing batch #7\n",
      "Processing batch #8\n",
      "Processing batch #9\n",
      "Processing batch #10\n",
      "Processing batch #11\n",
      "Processing batch #12\n",
      "Processing batch #13\n",
      "Processing batch #14\n",
      "Processing batch #15\n",
      "Processing batch #16\n",
      "Processing batch #17\n",
      "Processing batch #18\n",
      "Processing batch #19\n",
      "Processing batch #20\n",
      "Processing batch #21\n",
      "Processing batch #22\n",
      "Processing batch #23\n",
      "Processing batch #24\n",
      "Processing batch #25\n",
      "Processing batch #26\n",
      "Processing batch #27\n",
      "Processing batch #28\n",
      "Processing batch #29\n",
      "Processing batch #30\n",
      "Processing batch #31\n",
      "Processing batch #32\n",
      "Processing batch #33\n",
      "Processing batch #34\n",
      "Processing batch #35\n",
      "Processing batch #36\n",
      "Processing batch #37\n",
      "Processing batch #38\n",
      "Processing batch #39\n",
      "Processing batch #40\n",
      "Processing batch #41\n",
      "Processing batch #42\n",
      "Processing batch #43\n",
      "Processing batch #44\n",
      "Processing batch #45\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def _n_elements(tfrecords_list):\n",
    "    c = 0\n",
    "    for fn in tfrecords_list:\n",
    "        for _ in tf.python_io.tf_record_iterator(fn):\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def _parser(record, image_size):\n",
    "    # the 'features' here include your normal data feats along\n",
    "    # with the label for that data\n",
    "    features = {\n",
    "        'image': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed = tf.parse_single_example(record, features)\n",
    "\n",
    "    # The image (features)\n",
    "    image_decoded = tf.image.decode_jpeg(parsed['image'], channels=3)\n",
    "    image_resized = tf.image.resize_images(\n",
    "        image_decoded,\n",
    "        [image_size, image_size],\n",
    "        method=tf.image.ResizeMethod.BILINEAR,\n",
    "        align_corners=True\n",
    "    )\n",
    "    image_normalized = image_resized\n",
    "\n",
    "    # The label\n",
    "    label = tf.cast(parsed['label'], tf.int32)\n",
    "\n",
    "    return {'x': image_normalized}, label\n",
    "\n",
    "\n",
    "def _input_fn(tfrecord_data, length, batch_size=128, img_size=84):\n",
    "    dataset = tfrecord_data \n",
    "\n",
    "    dataset = dataset.map(lambda record: _parser(record, img_size))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 2. Get the dataset as tf.Dataset object\n",
    "img_size = 84\n",
    "dataset = _input_fn(\n",
    "    tfrecord_data, _n_elements(tfrecords_list), img_size=img_size\n",
    ")\n",
    "\n",
    "# Iterate over all images. For each batch, we append to the csv file to\n",
    "# avoid memory issues if the dataset is too big.\n",
    "c = 0\n",
    "for idx, batch in enumerate(dataset):\n",
    "    print(\"Processing batch #{i}\".format(i=idx+1))\n",
    "    for img, label in zip(batch[0]['x'], batch[1]):\n",
    "        if c > 4:\n",
    "            break\n",
    "        img_np = img.numpy()\n",
    "        img = Image.fromarray(img_np, 'RGB')\n",
    "        img.show()\n",
    "        c += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with TensorFlow's TFRecords, Dataset and Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T23:30:45.938938Z",
     "start_time": "2019-07-23T23:30:45.920294Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 84\n",
    "\n",
    "def n_elements(records_list):\n",
    "    \"\"\"Return the number of elements in a tensorflow records file.\"\"\"\n",
    "    count = 0\n",
    "    for tfrecords_file in records_list:\n",
    "        for _ in tf.python_io.tf_record_iterator(tfrecords_file):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def parser(record_dataset):\n",
    "    \"\"\"Parse a given TFRecordsDataset object.\"\"\"\n",
    "    # This is the definition we expect in the TFRecords for meta-dataset\n",
    "    features = {\n",
    "        'image': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    exp_image_size = 84\n",
    "\n",
    "    # 1. We parse the record_dataset with the features defined above.\n",
    "    parsed = tf.parse_single_example(record_dataset, features)\n",
    "\n",
    "    # 2. We will decode the image as a jpeg with 3 channels and resize it to\n",
    "    #    the expected image size\n",
    "    image_decoded = tf.image.decode_jpeg(parsed['image'], channels=3)\n",
    "    image_resized = tf.image.resize_images(\n",
    "        image_decoded,\n",
    "        [exp_image_size, exp_image_size],\n",
    "        method=tf.image.ResizeMethod.BILINEAR,\n",
    "        align_corners=True\n",
    "    )\n",
    "    # 3. And we normalize the dataset in the range [0, 1]\n",
    "    image_normalized = image_resized / 255.0\n",
    "\n",
    "    # 4. we make the label an int32.\n",
    "    label = tf.cast(parsed['label'], tf.int32)\n",
    "\n",
    "    # 5. We return as dataset a s pair ( {features}, label)\n",
    "    return {'x': image_normalized}, label\n",
    "\n",
    "\n",
    "def metadataset_input_fn(tfrecord_data, data_length, batch_size=128,\n",
    "                         is_train=True, split_prop=0.33, random_seed=32,\n",
    "                         is_distributed=False):\n",
    "    \"\"\"Input function for a tensorflow estimator.\"\"\"\n",
    "    trainset_length = math.floor(data_length*(1. - split_prop))\n",
    "\n",
    "    files = tf.data.Dataset.list_files(\n",
    "        tfrecord_data, shuffle=False\n",
    "    )\n",
    "    n_threads = multiprocessing.cpu_count()\n",
    "    print(\n",
    "        \"Number of threads available for dataset processing is %d\", n_threads\n",
    "    )\n",
    "    dataset = files.apply(\n",
    "        tf.contrib.data.parallel_interleave(\n",
    "            lambda filename: tf.data.TFRecordDataset(filename),\n",
    "            cycle_length=n_threads\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.shuffle(data_length, seed=random_seed, reshuffle_each_iteration=False)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.take(trainset_length)\n",
    "        current_length = trainset_length\n",
    "        dataset = dataset.apply(\n",
    "            tf.contrib.data.shuffle_and_repeat(current_length, 10)\n",
    "        )\n",
    "    else:\n",
    "        dataset = dataset.skip(trainset_length)\n",
    "        current_length = data_length - trainset_length\n",
    "\n",
    "    # shuffle and repeat examples for better randomness and allow training\n",
    "    # beyond one epoch\n",
    "#     count_repeat = 30 if is_train else 1\n",
    "\n",
    "    print(\"Current length in input_fn %d\", current_length)\n",
    "\n",
    "    # map the parse function to each example individually in threads*2\n",
    "    # parallel calls\n",
    "    dataset = dataset.map(\n",
    "        map_func=lambda example: parser(example),\n",
    "        num_parallel_calls=n_threads\n",
    "    )\n",
    "\n",
    "    # batch the examples if using training, otherwise we want to evaluate on\n",
    "    # the whole dataset in one single step\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    # prefetch batch\n",
    "    dataset = dataset.prefetch(buffer_size=32)\n",
    "\n",
    "    return dataset\n",
    "#     if is_distributed:\n",
    "#         return dataset\n",
    "\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "#     return iterator.get_next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T23:32:29.379866Z",
     "start_time": "2019-07-23T23:30:47.324911Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length is 5640\n",
      "Number of threads available for dataset processing is %d 4\n",
      "Current length in input_fn %d 3778\n",
      "Expected number of batches per epoch: 30\n",
      "Batch number 1\n",
      "Starting over the dataset.\n",
      "Batch number 31\n",
      "Starting over the dataset.\n",
      "Batch number 61\n",
      "Starting over the dataset.\n",
      "Batch number 91\n",
      "Starting over the dataset.\n",
      "Batch number 121\n",
      "Starting over the dataset.\n",
      "Batch number 151\n",
      "Starting over the dataset.\n",
      "Batch number 181\n",
      "Starting over the dataset.\n",
      "Batch number 211\n",
      "Starting over the dataset.\n",
      "Batch number 241\n",
      "Starting over the dataset.\n",
      "Batch number 271\n",
      "Starting over the dataset.\n",
      "List number 1\n",
      "Sum is 3840\n",
      "[74 89 83 81 89 86 83 86 80 84 73 82 80 87 80 70 85 72 76 85 82 90 90 80\n",
      " 81 82 83 82 74 78 81 83 87 84 84 85 78 79 76 77 87 88 81 87 76 82 78]\n",
      "List number 2\n",
      "Sum is 3840\n",
      "[70 93 80 84 91 88 82 90 82 82 74 79 85 87 82 71 84 71 75 83 81 87 88 82\n",
      " 84 85 84 85 73 81 78 81 85 77 83 86 79 80 78 74 89 84 76 86 80 85 76]\n",
      "List number 3\n",
      "Sum is 3840\n",
      "[76 85 85 76 94 86 79 83 77 82 76 81 77 84 76 73 85 69 79 88 86 95 89 79\n",
      " 82 85 85 82 76 79 80 81 94 87 84 86 75 80 74 77 86 91 77 89 75 77 78]\n",
      "List number 4\n",
      "Sum is 3840\n",
      "[74 89 79 81 86 86 87 84 83 88 70 76 84 89 79 69 84 73 75 87 82 86 94 82\n",
      " 82 81 83 80 77 80 81 86 83 81 92 89 77 76 80 74 86 85 78 90 72 85 75]\n",
      "List number 5\n",
      "Sum is 3840\n",
      "[68 91 84 85 94 85 82 87 80 79 79 85 85 82 77 71 84 73 79 80 79 88 86 75\n",
      " 85 83 86 85 73 81 79 77 89 82 77 79 82 83 79 79 91 87 80 82 78 82 83]\n",
      "List number 6\n",
      "Sum is 3840\n",
      "[77 92 84 80 86 83 78 87 85 87 74 78 78 94 81 74 83 69 75 93 80 93 88 83\n",
      " 79 83 83 79 72 78 84 84 83 71 84 88 72 76 79 77 87 91 79 91 82 82 74]\n",
      "List number 7\n",
      "Sum is 3840\n",
      "[70 83 88 84 92 92 84 88 70 81 79 81 75 87 82 66 83 70 75 83 88 89 88 86\n",
      " 83 84 82 84 78 81 78 84 89 91 92 84 74 75 78 76 86 85 81 84 69 80 78]\n",
      "List number 8\n",
      "Sum is 3840\n",
      "[76 97 74 77 93 86 84 79 85 85 78 80 91 78 76 74 86 74 79 82 80 88 99 77\n",
      " 78 84 92 84 73 76 80 78 91 73 75 81 84 90 70 74 87 85 70 90 79 87 81]\n",
      "List number 9\n",
      "Sum is 3840\n",
      "[75 85 84 87 89 81 80 89 75 81 64 80 77 86 84 72 90 68 74 85 85 90 82 87\n",
      " 87 83 85 81 72 76 80 87 83 85 83 83 72 74 84 80 95 96 79 91 77 84 73]\n",
      "List number 10\n",
      "Sum is 3220\n",
      "[60 76 69 65 76 77 71 77 73 71 63 68 68 76 63 60 66 61 63 74 67 74 76 59\n",
      " 69 70 67 68 62 70 69 69 76 69 76 79 67 67 62 62 66 68 69 70 62 66 64]\n",
      "N different observations seen: 3693\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_length = n_elements(tfrecords_list)\n",
    "print(\"Dataset length is\", dataset_length)\n",
    "\n",
    "dataset = metadataset_input_fn(\n",
    "    tfrecord_data=pattern,\n",
    "    data_length=dataset_length,\n",
    "    batch_size=128,\n",
    "    is_train=True,\n",
    "    split_prop=0.33,\n",
    "    random_seed=32,\n",
    "    is_distributed=False\n",
    ")\n",
    "\n",
    "exp_batches = math.ceil(dataset_length*(1-0.33)/128)\n",
    "print(\"Expected number of batches per epoch:\", exp_batches)\n",
    "\n",
    "counts_list = []\n",
    "classes_count = None\n",
    "obs_set = set()\n",
    "for i, batch in enumerate(dataset):\n",
    "    if i % exp_batches == 0:\n",
    "        print(\"Batch number\", i+1)\n",
    "        print(\"Starting over the dataset.\")\n",
    "        if classes_count is not None:\n",
    "            counts_list.append(classes_count)\n",
    "        classes_count = np.zeros(47, dtype=int)\n",
    "\n",
    "    for img, label in zip(batch[0]['x'], batch[1]):\n",
    "        img_np = img.numpy()\n",
    "        obs_set.add(str(img_np.flatten()))\n",
    "        label_np = int(label.numpy())\n",
    "        classes_count[label_np] += 1\n",
    "\n",
    "counts_list.append(classes_count)\n",
    "for i, c_list in enumerate(counts_list):\n",
    "    print(\"List number\", i+1)\n",
    "    print(\"Sum is\", sum(c_list))\n",
    "    print(c_list)\n",
    "\n",
    "print(\"N different observations seen:\", len(obs_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The repeat makes the batches of equal size, meaning that if the last batch is not complete it will fill the missing values to obtain a complete batch (e.g. complete batch of 128 elements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T23:32:45.834519Z",
     "start_time": "2019-07-23T23:32:40.483709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length is 5640\n",
      "Number of threads available for dataset processing is %d 4\n",
      "Current length in input_fn %d 1862\n",
      "Expected number of batches per epoch: 30\n",
      "Batch number 1\n",
      "Starting over the dataset.\n",
      "List number 1\n",
      "Sum is 1862\n",
      "[48 32 39 40 31 35 39 35 41 38 47 41 40 35 42 50 37 50 45 36 39 32 32 41\n",
      " 39 38 37 39 47 42 41 39 34 40 37 36 44 42 44 45 34 34 43 34 45 39 44]\n",
      "N different observations seen: 1828\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_length = n_elements(tfrecords_list)\n",
    "print(\"Dataset length is\", dataset_length)\n",
    "\n",
    "dataset = metadataset_input_fn(\n",
    "    tfrecord_data=pattern,\n",
    "    data_length=dataset_length,\n",
    "    batch_size=128,\n",
    "    is_train=False,\n",
    "    split_prop=0.33,\n",
    "    random_seed=32,\n",
    "    is_distributed=False\n",
    ")\n",
    "\n",
    "exp_batches = math.ceil(dataset_length*(1-0.33)/128)\n",
    "print(\"Expected number of batches per epoch:\", exp_batches)\n",
    "\n",
    "counts_list = []\n",
    "classes_count = None\n",
    "obs_set_test = set()\n",
    "for i, batch in enumerate(dataset):\n",
    "    if i % exp_batches == 0:\n",
    "        print(\"Batch number\", i+1)\n",
    "        print(\"Starting over the dataset.\")\n",
    "        if classes_count is not None:\n",
    "            counts_list.append(classes_count)\n",
    "        classes_count = np.zeros(47, dtype=int)\n",
    "\n",
    "    for img, label in zip(batch[0]['x'], batch[1]):\n",
    "        img_np = img.numpy()\n",
    "        obs_set_test.add(str(img_np.flatten()))\n",
    "        label_np = int(label.numpy())\n",
    "        classes_count[label_np] += 1\n",
    "\n",
    "counts_list.append(classes_count)\n",
    "for i, c_list in enumerate(counts_list):\n",
    "    print(\"List number\", i+1)\n",
    "    print(\"Sum is\", sum(c_list))\n",
    "    print(c_list)\n",
    "\n",
    "print(\"N different observations seen:\", len(obs_set_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T23:32:45.862101Z",
     "start_time": "2019-07-23T23:32:45.842425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff 1 3676\n",
      "Diff 2 1811\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff 1\", len(obs_set.difference(obs_set_test)))\n",
    "print(\"Diff 2\", len(obs_set_test.difference(obs_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
