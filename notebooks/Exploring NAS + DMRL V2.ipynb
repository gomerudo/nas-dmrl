{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring results for NAS with DMRL [V2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for interactive notebook (see:\n",
    "# https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html)\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout\n",
    "\n",
    "# Import to list files in directories\n",
    "import glob\n",
    "\n",
    "# Import for regular expressions\n",
    "import re\n",
    "\n",
    "# Imports for path operations\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# For date operations\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"/Users/gomerudo/workspace/thesis_results\"\n",
    "\n",
    "def rettext(text):\n",
    "    return text\n",
    "\n",
    "def search_in_file(file, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    results = []\n",
    "    for i, line in enumerate(open(file)):\n",
    "        for match in re.finditer(pattern, line):\n",
    "            results.append(match.groups())\n",
    "    return results\n",
    "\n",
    "form_item_layout = Layout(\n",
    "    width=\"50%\"\n",
    ")\n",
    "\n",
    "w_resdirs = interactive(\n",
    "    rettext,\n",
    "    text=sorted(glob.glob(\"{dir}/[0-9]*\".format(dir=RESULTS_DIR))),\n",
    "    layout=form_item_layout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5dcd71a1c54822bfadf24dc8d782ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='text', options=('/Users/gomerudo/workspace/thesis_results/25407', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(w_resdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Note**: In order to get the results, run all cells below once you have selected the desired directory in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and parsing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "############ OBTAIN THE FILES AND DIRECTORIES TO QUERY FOR ANALYSIS ############\n",
    "################################################################################\n",
    "\n",
    "# Obtain the chosen directory\n",
    "chosen_dir = w_resdirs.result\n",
    "\n",
    "# experiments dir\n",
    "exp_dir = glob.glob(\"{dir}/experiment*[!.zip]\".format(dir=chosen_dir))[0]\n",
    "\n",
    "# This is a list of all openai dirs, sorted by name (hence, by timestamp)\n",
    "openai_dirs = sorted(glob.glob(\"{dir}/openai*[!.zip]\".format(dir=exp_dir)))\n",
    "if not len(openai_dirs):\n",
    "    openai_dirs = sorted(glob.glob(\"{dir}/opeanai*[!.zip]\".format(dir=exp_dir)))\n",
    "\n",
    "# A simple DB of experiments and actions_info.csv should be there\n",
    "dbexp_file = glob.glob(\"{dir}/db*\".format(dir=exp_dir))[0]\n",
    "ainfo_file = glob.glob(\"{dir}/act*\".format(dir=exp_dir))[0]\n",
    "#episode_logs = glob.glob(\"{dir}/episode_logs/*\".format(dir=openai_dir))\n",
    "\n",
    "flog_file = glob.glob(\"{dir}/sl*\".format(dir=chosen_dir))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "########### BUILD THE RELEVANT DATA FRAMES TO PRINT FOR MAIN SUMMARY ###########\n",
    "################################################################################\n",
    "\n",
    "# 1. Make dataframes for the db of experiments and the actions summary\n",
    "dbexp_df = pd.read_csv(dbexp_file)\n",
    "ainfo_df = pd.read_csv(ainfo_file)\n",
    "\n",
    "# 2. Build used GPU's dataframe\n",
    "gpu_devices = search_in_file(flog_file, \"Found device\\s+(.+)\\s+with\")\n",
    "gpu_props = search_in_file(flog_file, \"name:\\s+(.+)\\s+major:\\s+(.+)\\s+minor:\\s+(.*)\\s+memo.*:\\s+(.*)\")\n",
    "\n",
    "gpus_df = pd.DataFrame(columns=[\"ID\", \"Name\", \"Major\", \"Minor\", \"MemoryClockRate (GHz)\"])\n",
    "for device, props in zip(gpu_devices, gpu_props):\n",
    "    gpus_df = gpus_df.append(\n",
    "        {\n",
    "            \"ID\": device[0],\n",
    "            \"Name\": props[0],\n",
    "            \"Major\": props[1],\n",
    "            \"Minor\": props[2],\n",
    "            \"MemoryClockRate (GHz)\": props[3],\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "# Try to obtain the current times\n",
    "running_times = search_in_file(flog_file, \".*\\s+(.*)elapsed\")\n",
    "if len(running_times) == len(openai_dirs):\n",
    "    f_running_times = []\n",
    "    for time in running_times:\n",
    "        time_cleansed = time[0].split(\".\")[0]\n",
    "        f_running_times.append(time_cleansed)\n",
    "else:\n",
    "    prev_timestamp = 0\n",
    "    f_running_times = []\n",
    "    for directory in openai_dirs:\n",
    "        exp_dirname_only = os.path.basename(directory)\n",
    "        timestamp = os.path.basename(exp_dirname_only.split(\"-\")[1])\n",
    "        d2 = datetime.strptime(timestamp, \"%Y%m%d%H%M%S\")\n",
    "        if prev_timestamp:  # 2019 05 29 211533\n",
    "            d1 = datetime.strptime(prev_timestamp, \"%Y%m%d%H%M%S\")\n",
    "            f_running_times.append(str(d2 - d1))\n",
    "        prev_timestamp = timestamp\n",
    "    f_running_times.append(\"NA\")\n",
    "    \n",
    "openai_dirs_df = pd.DataFrame(zip(openai_dirs, f_running_times), columns=[\"Log directory\", \"Runtime\"])\n",
    "\n",
    "# 4. Search all exceptions\n",
    "exceptions_all = search_in_file(flog_file, \"failed with exception of type.*<(.*)>.*Message.*:\\s*(.*)\")\n",
    "\n",
    "exceptions_set = set()\n",
    "for error, message in exceptions_all:\n",
    "    exceptions_set.add(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "ainfo_df.shape[0]": "116",
     "chosen_dir": "/Users/gomerudo/workspace/thesis_results/25943",
     "dbexp_df.shape[0]": "1608",
     "flog_file": "/Users/gomerudo/workspace/thesis_results/25943/slurm-25943.out",
     "gpus_df": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Name</th>\n      <th>Major</th>\n      <th>Minor</th>\n      <th>MemoryClockRate (GHz)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>Tesla V100-DGXS-16GB</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.53</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "openai_dirs_df": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Log directory</th>\n      <th>Runtime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190612211809</td>\n      <td>0:08:28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190612212637</td>\n      <td>0:07:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190612213337</td>\n      <td>0:24:04</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190612215741</td>\n      <td>0:10:12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190612220753</td>\n      <td>0:20:37</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190612222830</td>\n      <td>2:41:18</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190613010948</td>\n      <td>13:25:47</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/openai-20190613143535</td>\n      <td>NA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "#### Highglights\n",
    "\n",
    "- **Chosen results directory is:** {{chosen_dir}}\n",
    "- **Full log is available at:** {{flog_file}}\n",
    "- **Total number of experiments in DB:** {{dbexp_df.shape[0]}}\n",
    "- **Total number of actions considered:** {{ainfo_df.shape[0]}}\n",
    "\n",
    "#### Configuration used\n",
    "\n",
    "\n",
    "#### GPU's information\n",
    "\n",
    "{{gpus_df}}\n",
    "\n",
    "#### Individual run directories\n",
    "\n",
    "{{openai_dirs_df}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "pd.DataFrame(exceptions_set, columns = [\"Error type\"])": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Error type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>class 'ZeroDivisionError'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>class 'ValueError'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>class 'KeyError'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "### Errors found in log while building networks\n",
    "\n",
    "{{pd.DataFrame(exceptions_set, columns = [\"Error type\"])}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "dbexp_df.loc[dbexp_df['is_valid'] == False].shape[0]": "1054",
     "dbexp_df.loc[dbexp_df['is_valid'] == True].shape[0]": "554",
     "dbexp_df.shape[0]": "1608",
     "dbexp_file": "/Users/gomerudo/workspace/thesis_results/25943/experiment-20190612211807/db_experiments.csv"
    }
   },
   "source": [
    "### The database of experiments\n",
    "\n",
    "- **Full database available at:** {{dbexp_file}}\n",
    "- **Total number of experiments in DB:** {{dbexp_df.shape[0]}}\n",
    "- **Number of valid sampled architectures:** {{dbexp_df.loc[dbexp_df['is_valid'] == True].shape[0]}}\n",
    "- **Number of non-valid sampled architectures:** {{dbexp_df.loc[dbexp_df['is_valid'] == False].shape[0]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best reward obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_by_reward = dbexp_df.sort_values(by='reward', ascending=False)\n",
    "best_arch_by_reward = best_by_reward.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "best_arch_by_reward.name": "686",
     "best_arch_by_reward['accuracy']": "0.24869999289512634",
     "best_arch_by_reward['dataset-nethash']": "cifar10-841404c9877e5a15c3401a03d183845e",
     "best_arch_by_reward['density']": "1.0",
     "best_arch_by_reward['flops']": "768000.0",
     "best_arch_by_reward['is_valid']": "True",
     "best_arch_by_reward['reward']": "18.09422678344773",
     "best_arch_by_reward['running_time']": "2",
     "best_arch_by_reward['timestamp']": "2019-06-12 22:37:44",
     "for layer in best_arch_by_reward['netstring'].split(\"\\n\"):  print(layer)": "[[0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [1 3 3 0 0]\n [2 3 1 1 0]]"
    }
   },
   "source": [
    "**Main information**\n",
    "\n",
    "- **ID:** {{best_arch_by_reward['dataset-nethash']}}\n",
    "- **Index in DB:** {{best_arch_by_reward.name}}\n",
    "- **Is valid?** {{best_arch_by_reward['is_valid']}}\n",
    "- **Reward:** {{best_arch_by_reward['reward']}}\n",
    "- **Accuracy:** {{best_arch_by_reward['accuracy']}}\n",
    "- **Training time (in sec):** {{best_arch_by_reward['running_time']}}\n",
    "\n",
    "**The architecture**\n",
    "\n",
    "```{{for layer in best_arch_by_reward['netstring'].split(\"\\n\"):  print(layer)}}```\n",
    "\n",
    "**Other information**\n",
    "\n",
    "- **Timestamp:** {{best_arch_by_reward['timestamp']}}\n",
    "- **Density:** {{best_arch_by_reward['density']}}\n",
    "- **FLOPs:** {{best_arch_by_reward['flops']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best obtained accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_by_accuracy = dbexp_df.sort_values(by='accuracy', ascending=False)\n",
    "best_arch_by_accuracy = best_by_accuracy.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "best_arch_by_accuracy.name": "1320",
     "best_arch_by_accuracy['accuracy']": "0.2766000032424927",
     "best_arch_by_accuracy['dataset-nethash']": "cifar10-28dae67181352ff57990248bc7ca5331",
     "best_arch_by_accuracy['density']": "1.265",
     "best_arch_by_accuracy['flops']": "236359454.0",
     "best_arch_by_accuracy['is_valid']": "True",
     "best_arch_by_accuracy['reward']": "17.902032105957762",
     "best_arch_by_accuracy['running_time']": "93",
     "best_arch_by_accuracy['timestamp']": "2019-06-13 08:13:07",
     "for layer in best_arch_by_accuracy['netstring'].split(\"\\n\"):  print(layer)": "[[0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [0 0 0 0 0]\n [1 2 1 0 0]\n [2 1 1 1 0]\n [3 1 1 0 0]\n [4 3 3 1 0]]"
    }
   },
   "source": [
    "**Main information**\n",
    "\n",
    "- **ID:** {{best_arch_by_accuracy['dataset-nethash']}}\n",
    "- **Index in DB:** {{best_arch_by_accuracy.name}}\n",
    "- **Is valid?** {{best_arch_by_accuracy['is_valid']}}\n",
    "- **Reward:** {{best_arch_by_accuracy['reward']}}\n",
    "- **Accuracy:** {{best_arch_by_accuracy['accuracy']}}\n",
    "- **Training time (in sec):** {{best_arch_by_accuracy['running_time']}}\n",
    "\n",
    "**The architecture**\n",
    "\n",
    "```{{for layer in best_arch_by_accuracy['netstring'].split(\"\\n\"):  print(layer)}}```\n",
    "\n",
    "**Other information**\n",
    "\n",
    "- **Timestamp:** {{best_arch_by_accuracy['timestamp']}}\n",
    "- **Density:** {{best_arch_by_accuracy['density']}}\n",
    "- **FLOPs:** {{best_arch_by_accuracy['flops']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "len(openai_dirs)": "8"
    }
   },
   "source": [
    "- **Total number of trials:** {{len(openai_dirs)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def analyze_trial(trial_logs, trial_n):\n",
    "    # We'll use this for the distribution of actions per trial\n",
    "    actions_log = [0]*ainfo_df.shape[0]\n",
    "\n",
    "    # This will store the max_step achieved per episode.\n",
    "    max_step_count_history = []\n",
    "    best_reward_history = []\n",
    "    all_rewards_history = []\n",
    "    step_in_ep = 0\n",
    "    reward_in_ep = 0\n",
    "    for log_file in trial_logs:\n",
    "        try:\n",
    "            ep_df = pd.read_csv(\"{f}\".format(f=log_file))\n",
    "\n",
    "            for idx, row in ep_df.iterrows():\n",
    "                # 1. Add information to the distribution of actions\n",
    "                action_id = int(row['action_id'])\n",
    "                actions_log[action_id] += 1\n",
    "\n",
    "                # 2. Keep the rewards\n",
    "                c_reward = int(row['reward'])\n",
    "                all_rewards_history.append(c_reward)\n",
    "                \n",
    "                # 3. Keep the best information and count episodes\n",
    "                c_sc = int(row['step_count'])\n",
    "                \n",
    "                # 4. If we keep counting steps, accumulate information\n",
    "                if c_sc > step_in_ep:\n",
    "                    step_in_ep = c_sc\n",
    "                    reward_in_ep = c_reward if c_reward > reward_in_ep else reward_in_ep\n",
    "                # Otherwise, append the best information we read\n",
    "                else:\n",
    "                    max_step_count_history.append(step_in_ep)\n",
    "                    best_reward_history.append(reward_in_ep)\n",
    "                    step_in_ep = c_sc\n",
    "                    reward_in_ep = 0\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "\n",
    "    return actions_log, max_step_count_history, best_reward_history, all_rewards_history\n",
    "\n",
    "\n",
    "stats = []\n",
    "for i, openai_dir in enumerate(openai_dirs):\n",
    "    episode_logs = sorted(glob.glob(\"{dir}/episode_logs/*\".format(dir=openai_dir)))\n",
    "    actions_log, max_step_count_history, best_reward_history, all_rewards_history = analyze_trial(episode_logs, i+1)\n",
    "    stats.append(\n",
    "        {\n",
    "            'actions_log': actions_log,\n",
    "            'max_step_history': max_step_count_history,\n",
    "            'best_reward_history': best_reward_history,\n",
    "            'all_rewards_history': all_rewards_history\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4d4e6a1fb243b688ba28eed85c4792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='trial', options=(1, 2, 3, 4, 5, 6, 7, 8), value=1), Output()), _doâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def trial_plots(trial=list(range(1, len(stats) + 1))):\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = 2, ncols=2)\n",
    "    plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.8)\n",
    "    \n",
    "    fig.set_size_inches(16, 6)\n",
    "    fig.suptitle(\n",
    "        \"Results for trial {t}\\nNumber of episodes: {e}\".format(\n",
    "            t=trial,\n",
    "            e=len(stats[trial-1]['best_reward_history'])\n",
    "        ),\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "    # Plot the actions distribution\n",
    "    dact_ax = axes[0][0]\n",
    "    dact_ax.set_title(\"Distribution of actions taken during trial\")\n",
    "    dact_ax.set_xlabel(\"Action ID\")\n",
    "    dact_ax.set_ylabel(\"Count\")\n",
    "\n",
    "    dact_ax.bar(\n",
    "        range(len(stats[trial-1]['actions_log'])),\n",
    "        stats[trial-1]['actions_log']\n",
    "    )\n",
    "    \n",
    "    # Plot the max_step evolution\n",
    "    maxsteps_ax = axes[0][1]\n",
    "    maxsteps_ax.set_title(\"Evolution of max_step achieved through episodes\")\n",
    "    maxsteps_ax.set_xlabel(\"Episode\")\n",
    "    maxsteps_ax.set_ylabel(\"Max Step achieved\")\n",
    "    maxsteps_ax.plot(\n",
    "        range(len(stats[trial-1]['max_step_history'])),\n",
    "        stats[trial-1]['max_step_history']\n",
    "    )\n",
    "\n",
    "    # Plot the best reward evolution\n",
    "    bestrew_ax = axes[1][0]\n",
    "    bestrew_ax.set_title(\"Evolution of best reward through episodes\")\n",
    "    bestrew_ax.set_xlabel(\"Episode\")\n",
    "    bestrew_ax.set_ylabel(\"Reward\")\n",
    "    bestrew_ax.plot(\n",
    "        range(len(stats[trial-1]['best_reward_history'])),\n",
    "        stats[trial-1]['best_reward_history']\n",
    "    )\n",
    "\n",
    "    # Plot the histogram of rewards\n",
    "    bestrew_ax = axes[1][1]\n",
    "    bestrew_ax.set_title(\"Distribution of obtained rewards during trial\")\n",
    "    bestrew_ax.set_xlabel(\"Episode\")\n",
    "    bestrew_ax.set_ylabel(\"Count\")\n",
    "    bestrew_ax.hist(\n",
    "        stats[trial-1]['all_rewards_history']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
