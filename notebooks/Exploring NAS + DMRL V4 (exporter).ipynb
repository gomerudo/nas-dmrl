{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring results for NAS with DMRL [V3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:20:26.388331Z",
     "start_time": "2019-07-18T12:20:26.345870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import for interactive notebook (see:\n",
    "# https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html)\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout\n",
    "\n",
    "# Import to list files in directories\n",
    "import glob\n",
    "\n",
    "# Import for regular expressions\n",
    "import re\n",
    "\n",
    "# Imports for path operations\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# For date operations\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import configparser\n",
    "\n",
    "# import jtplot module in notebook\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# choose which theme to inherit plotting style from\n",
    "# onedork | grade3 | oceans16 | chesterish | monokai | solarizedl | solarizedd\n",
    "jtplot.style(theme='onedork')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:20:26.702645Z",
     "start_time": "2019-07-18T12:20:26.611518Z"
    }
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"/Users/gomerudo/workspace/thesis_results\"\n",
    "\n",
    "def rettext(text):\n",
    "    return text\n",
    "\n",
    "def search_in_file(file, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    results = []\n",
    "    for i, line in enumerate(open(file)):\n",
    "        for match in re.finditer(pattern, line):\n",
    "            results.append(match.groups())\n",
    "    return results\n",
    "\n",
    "form_item_layout = Layout(\n",
    "    width=\"50%\"\n",
    ")\n",
    "\n",
    "w_resdirs = interactive(\n",
    "    rettext,\n",
    "#     text=sorted(glob.glob(\"{dir}/[mix-]?[0-9]*\".format(dir=RESULTS_DIR))),\n",
    "    text=sorted(glob.glob(\"{dir}/*\".format(dir=RESULTS_DIR))),\n",
    "    layout=form_item_layout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:20:27.550189Z",
     "start_time": "2019-07-18T12:20:27.531658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd95cf50624e43dd9e1714f10e1a1065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='text', options=('/Users/gomerudo/workspace/thesis_results/26630', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(w_resdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:46:03.329079Z",
     "start_time": "2019-07-18T12:46:03.296214Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "############ OBTAIN THE FILES AND DIRECTORIES TO QUERY FOR ANALYSIS ############\n",
    "################################################################################\n",
    "\n",
    "# Obtain the chosen directory\n",
    "chosen_dir = w_resdirs.result\n",
    "\n",
    "# experiments dir\n",
    "exp_dir = glob.glob(\"{dir}/experiment*[!.zip]\".format(dir=chosen_dir))[0]\n",
    "\n",
    "# This is a list of all openai dirs, sorted by name (hence, by timestamp)\n",
    "openai_dirs = sorted(glob.glob(\"{dir}/openai*[!.zip]\".format(dir=exp_dir)))\n",
    "\n",
    "# A simple DB of experiments and actions_info.csv should be there\n",
    "dbexp_file = glob.glob(\"{dir}/db_experiments.csv\".format(dir=exp_dir))[0]\n",
    "ainfo_file = glob.glob(\"{dir}/actions_info.csv\".format(dir=exp_dir))[0]\n",
    "config_file = glob.glob(\"{dir}/config.ini\".format(dir=exp_dir))[0]\n",
    "flog_file = glob.glob(\"{dir}/sl*\".format(dir=chosen_dir))[0]\n",
    "\n",
    "# Make dataframes for the db of experiments and the actions summary\n",
    "dbexp_df = pd.read_csv(dbexp_file)\n",
    "ainfo_df = pd.read_csv(ainfo_file)\n",
    "\n",
    "# Make de target directory\n",
    "import os\n",
    "summaries_dir = \"{exp}/summary\".format(exp=chosen_dir)\n",
    "if not os.path.isdir(summaries_dir):\n",
    "    os.mkdir(summaries_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:46:03.837523Z",
     "start_time": "2019-07-18T12:46:03.654616Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "########### BUILD THE RELEVANT DATA FRAMES TO PRINT FOR MAIN SUMMARY ###########\n",
    "################################################################################\n",
    "    \n",
    "# Try to obtain the current times\n",
    "# running_times = search_in_file(flog_file, \".*\\s+(.*)elapsed\")\n",
    "# if len(running_times) == len(openai_dirs):\n",
    "#     f_running_times = []\n",
    "#     for time in running_times:\n",
    "#         time_cleansed = time[0].split(\".\")[0]\n",
    "#         f_running_times.append(time_cleansed)\n",
    "# else:\n",
    "prev_timestamp = 0\n",
    "f_running_times = []\n",
    "for directory in openai_dirs:\n",
    "    exp_dirname_only = os.path.basename(directory)\n",
    "    timestamp = os.path.basename(exp_dirname_only.split(\"-\")[1])\n",
    "    d2 = datetime.strptime(timestamp, \"%Y%m%d%H%M%S\")\n",
    "    if prev_timestamp:  # 2019 05 29 211533\n",
    "        d1 = datetime.strptime(prev_timestamp, \"%Y%m%d%H%M%S\")\n",
    "        f_running_times.append(str(d2 - d1))\n",
    "    prev_timestamp = timestamp\n",
    "f_running_times.append(\"NA\")\n",
    "\n",
    "openai_dirs_df = pd.DataFrame(zip(openai_dirs, f_running_times), columns=[\"Log directory\", \"Runtime\"])\n",
    "\n",
    "# 4. Search all exceptions\n",
    "exceptions_all = search_in_file(flog_file, \"failed with exception of type.*<(.*)>.*Message.*:\\s*(.*)\")\n",
    "n_exceptions = len(exceptions_all)\n",
    "\n",
    "exceptions_set = set()\n",
    "for error, message in exceptions_all:\n",
    "    exceptions_set.add(error)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "_ = config.read(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "ainfo_df.shape[0]": "8",
     "chosen_dir": "/Users/gomerudo/workspace/thesis_results/6522472",
     "config['DEFAULT']['LogPath']": "/home/jgomes/workspace/git_storage/openai-baselines/workspace_mdn10",
     "config['bash']['Algorithm']": "meta_a2c",
     "config['bash']['Environment']": "NAS_cifar10-v1",
     "config['bash']['NSteps']": "10",
     "config['bash']['Network']": "meta_lstm",
     "config['bash']['NumTimesteps']": "3e2",
     "config['metadataset']['DatasetID']": "traffic_sign",
     "config['metadataset']['TFRecordsRootDir']": "/home/jgomes/workspace/metadataset_storage/records",
     "config['nasenv.default']['ActionSpaceType']": "chained",
     "config['nasenv.default']['ConfigFile']": "/home/jgomes/workspace/git_storage/nas-dmrl/configs/metadataset_n10/nasenv.yml",
     "config['nasenv.default']['DatasetHandler']": "meta-dataset",
     "config['nasenv.default']['DbFile']": "/home/jgomes/workspace/git_storage/openai-baselines/workspace_mdn10/db_experiments.csv",
     "config['nasenv.default']['MaxSteps']": "100",
     "config['nasenv.default']['TrainerType']": "default",
     "config['trainer.default']['BatchSize']": "256",
     "config['trainer.default']['NEpochs']": "12",
     "config['trainer.tensorflow']['EnableDistributed']": "no",
     "flog_file": "/Users/gomerudo/workspace/thesis_results/6522472/slurm-6522472.out",
     "n_exceptions": "44",
     "openai_dirs_df": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Log directory</th>\n      <th>Runtime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/Users/gomerudo/workspace/thesis_results/6522472/experiment-20190718020233/openai-20190718020233</td>\n      <td>1:57:06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/Users/gomerudo/workspace/thesis_results/6522472/experiment-20190718020233/openai-20190718035939</td>\n      <td>1:50:36</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/Users/gomerudo/workspace/thesis_results/6522472/experiment-20190718020233/openai-20190718055015</td>\n      <td>2:27:05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/Users/gomerudo/workspace/thesis_results/6522472/experiment-20190718020233/openai-20190718081720</td>\n      <td>2:33:52</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/Users/gomerudo/workspace/thesis_results/6522472/experiment-20190718020233/openai-20190718105112</td>\n      <td>NA</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
     "pd.DataFrame(exceptions_set, columns = [\"Error type\"])": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Error type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>class 'ValueError'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- **Chosen results directory is:** {{chosen_dir}}\n",
    "- **Full log is available at:** {{flog_file}}\n",
    "\n",
    "#### Configuration\n",
    "\n",
    "- **Log Path:** {{config['DEFAULT']['LogPath']}}\n",
    "- **Environment:** {{config['bash']['Environment']}}\n",
    "\n",
    "##### Reinforcement Learning\n",
    "\n",
    "- **Algorithm:** {{config['bash']['Algorithm']}}\n",
    "- **Policy representation:** {{config['bash']['Network']}}\n",
    "- **Number of steps:** {{config['bash']['NSteps']}}\n",
    "- **Total number of timestamps:** {{config['bash']['NumTimesteps']}}\n",
    "- **Number of actions:** {{ainfo_df.shape[0]}}\n",
    "\n",
    "##### NAS details\n",
    "\n",
    "- **Config file:** {{config['nasenv.default']['ConfigFile']}}\n",
    "- **Max Steps:** {{config['nasenv.default']['MaxSteps']}}\n",
    "- **DB of experiments:** {{config['nasenv.default']['DbFile']}}\n",
    "- **Dataset Handler:** {{config['nasenv.default']['DatasetHandler']}}\n",
    "- **Action Space Type:** {{config['nasenv.default']['ActionSpaceType']}}\n",
    "- **Trainer:** {{config['nasenv.default']['TrainerType']}}\n",
    "\n",
    "##### Training details\n",
    "\n",
    "- **Batch size:** {{config['trainer.default']['BatchSize']}}\n",
    "- **Epochs:** {{config['trainer.default']['NEpochs']}}\n",
    "- **Distributed:** {{config['trainer.tensorflow']['EnableDistributed']}}\n",
    "\n",
    "##### Meta-dataset details\n",
    "\n",
    "- **TFRecordsRootDir:** {{config['metadataset']['TFRecordsRootDir']}}\n",
    "- **DatasetID:** {{config['metadataset']['DatasetID']}}\n",
    "\n",
    "#### Individual run directories/time\n",
    "\n",
    "{{openai_dirs_df}}\n",
    "\n",
    "#### Errors found in log while building networks\n",
    "\n",
    "- **Total number of exceptions:** {{n_exceptions}}\n",
    "\n",
    "{{pd.DataFrame(exceptions_set, columns = [\"Error type\"])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:21:18.160183Z",
     "start_time": "2019-07-18T12:21:17.832583Z"
    }
   },
   "outputs": [],
   "source": [
    "def trial_summary(trial_log):\n",
    "    # Read in try catch because the file can be corrupted or might not exist\n",
    "    try:\n",
    "        # Read the log file\n",
    "        trial_df = pd.read_csv(trial_log)\n",
    "        actions_distribution = [0]*ainfo_df.shape[0]\n",
    "        \n",
    "        # CONTROL VARIABLES\n",
    "        # Info for the best architecture\n",
    "        best_architecture = None\n",
    "        best_reward = -1\n",
    "\n",
    "        # Aux for episode control\n",
    "        max_step_ep = 0\n",
    "        best_reward_ep = 0\n",
    "\n",
    "        # History lists\n",
    "        max_step_count_history = []\n",
    "        best_reward_history = []\n",
    "        all_rewards_history = []\n",
    "\n",
    "        # Accumulated rewards per trial\n",
    "        acc_rewards_history = []\n",
    "        acc_reward = 0\n",
    "        # Iterate the log\n",
    "        for idx, row in trial_df.iterrows():\n",
    "            \n",
    "            # Obtain the information information\n",
    "            action_id = int(row['action_id'])\n",
    "            step = int(row['step_count'])\n",
    "            is_valid = bool(row['valid'])\n",
    "            arch_hash = row['end_state_hashed']\n",
    "            reward = float(row['reward'])\n",
    "            \n",
    "            # THIS SECTION IS FOR THE \"OVERALL\" STATISTICS IN TRIAL\n",
    "            # a) Add information to the distribution of actions\n",
    "            actions_distribution[action_id] += 1\n",
    "    \n",
    "            # b) Get the best reward by comparing one by one\n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                best_architecture = arch_hash\n",
    "\n",
    "            # c) History of all rewards in trial\n",
    "            all_rewards_history.append(reward)\n",
    "            \n",
    "            # d) Unique architectures\n",
    "            unique_architectures.add(arch_hash)\n",
    "\n",
    "            # THIS SECTION IS FOR THE EPISODE STATISTICS\n",
    "            if step > max_step_ep:\n",
    "                max_step_ep = step\n",
    "                best_reward_ep = reward if reward > best_reward_ep else best_reward_ep\n",
    "                acc_reward += reward\n",
    "            # Otherwise, append the best information we read\n",
    "            else:\n",
    "                max_step_count_history.append(max_step_ep)\n",
    "                best_reward_history.append(best_reward_ep)\n",
    "                acc_rewards_history.append(acc_reward)\n",
    "                max_step_ep = step\n",
    "                best_reward_ep = reward\n",
    "                acc_reward = reward\n",
    "    except Exception:\n",
    "        pass\n",
    "    finally:\n",
    "        return {\n",
    "            'actions_distribution': actions_distribution,\n",
    "            'max_step_history': max_step_count_history,\n",
    "            'best_reward_history': best_reward_history,\n",
    "            'all_rewards_history': all_rewards_history,\n",
    "            'best_architecture': best_architecture,\n",
    "            'best_reward': best_reward,\n",
    "            'n_episodes': len(best_reward_history),\n",
    "            'unique_architectures': set(trial_df['end_state_hashed'].unique()),\n",
    "            'acc_rewards_history': acc_rewards_history,\n",
    "        }\n",
    "\n",
    "# Obtain statistics for each trial \n",
    "stats = []\n",
    "for i, openai_dir in enumerate(openai_dirs):\n",
    "    try:\n",
    "        trial_log = sorted(glob.glob(\"{dir}/episode_logs/*\".format(dir=openai_dir)))[0]\n",
    "        info_trial = trial_summary(trial_log)\n",
    "        stats.append(info_trial)\n",
    "    except IndexError:\n",
    "        print(\"Could not read the episode_logs in {}\".format(openai_dir))\n",
    "        pass\n",
    "    \n",
    "# Build global statistics for the whole experiment\n",
    "n_episodes_history = []\n",
    "unique_architectures = set()\n",
    "last_length_set_archs = len(unique_architectures)\n",
    "best_global_architecture = None\n",
    "best_global_reward = 0\n",
    "\n",
    "global_best_reward_history = []\n",
    "global_all_rewards_history = []\n",
    "global_max_step_history = []\n",
    "new_archs_history = []\n",
    "\n",
    "for trial_stats in stats:\n",
    "    # Miscellaneous\n",
    "    n_episodes_history.append(len(trial_stats['best_reward_history']))\n",
    "    unique_architectures.update(trial_stats['unique_architectures'])\n",
    "    new_sampled_architectures = len(unique_architectures) - last_length_set_archs\n",
    "    last_length_set_archs = len(unique_architectures)\n",
    "    new_archs_history.append(new_sampled_architectures)\n",
    "    \n",
    "    # Best values\n",
    "    if trial_stats['best_reward'] > best_global_reward:\n",
    "        best_global_reward = trial_stats['best_reward']\n",
    "        best_global_architecture = trial_stats['best_architecture']\n",
    "        \n",
    "    # Global histories\n",
    "    global_best_reward_history += trial_stats['best_reward_history']\n",
    "    global_max_step_history += trial_stats['max_step_history']\n",
    "    \n",
    "    \n",
    "    # The distribution of actions\n",
    "total_n_episodes = sum(n_episodes_history)\n",
    "\n",
    "# Search for the best architecture\n",
    "best_architecture_id = \"{d}-{h}\".format(d=config['metadataset']['DatasetID'], h=best_global_architecture)\n",
    "best_architecture_dbexp = dbexp_df.loc[dbexp_df['dataset-nethash'] == best_architecture_id].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:21:25.842662Z",
     "start_time": "2019-07-18T12:21:18.161872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export the relevant information into CSVs so that we can plot them in a different tool\n",
    "\n",
    "# THE ACTIONS DATAFRAME\n",
    "acts_col = [\"action_{a}_count\".format(a=i) for i in range(ainfo_df.shape[0])]\n",
    "actions_count_df = pd.DataFrame()\n",
    "for i, trial in enumerate(stats):\n",
    "    for action, count in enumerate(trial['actions_distribution']):\n",
    "        actions_count_df = actions_count_df.append(\n",
    "            {\n",
    "                \"dataset\": config['metadataset']['DatasetID'],\n",
    "                \"trial\": i+1,\n",
    "                \"action_id\": \"A\"+ str(action),\n",
    "                \"count\": count/sum(trial['actions_distribution']),\n",
    "            },\n",
    "            ignore_index=True\n",
    "        )\n",
    "actions_count_df.to_csv(\"{dir}/actions_dist.csv\".format(dir=summaries_dir), index=False)\n",
    "\n",
    "# The TRIAL short stats\n",
    "trials_history_df = pd.DataFrame()\n",
    "for i, nepisodes in enumerate(n_episodes_history):\n",
    "    trials_history_df = trials_history_df.append(\n",
    "        {\n",
    "            \"trial\": i+1,\n",
    "            \"dataset\": config['metadataset']['DatasetID'],\n",
    "            \"attribute\": \"nepisodes\",\n",
    "            \"value\": nepisodes,\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "for i, narchs in enumerate(new_archs_history):\n",
    "    trials_history_df = trials_history_df.append(\n",
    "        {\n",
    "            \"trial\": i+1,\n",
    "            \"dataset\": config['metadataset']['DatasetID'],\n",
    "            \"attribute\": \"narchitectures\",\n",
    "            \"value\": narchs,\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "trials_history_df.to_csv(\"{dir}/trials_stats.csv\".format(dir=summaries_dir), index=False)\n",
    "\n",
    "### TRY AMBITIOUS STATISTICS\n",
    "steps_stats_df = pd.DataFrame()\n",
    "step_count = 0\n",
    "for i, trial_stats in enumerate(stats):\n",
    "    all_rewards = trial_stats['all_rewards_history']\n",
    "    for step, reward in enumerate(all_rewards):\n",
    "        step_count += 1\n",
    "        steps_stats_df = steps_stats_df.append(\n",
    "            {\n",
    "                \"dataset\": config['metadataset']['DatasetID'],\n",
    "                \"trial\": i+1,\n",
    "                \"step\": step+1,\n",
    "                \"acc_step\": step_count,\n",
    "                \"reward\": reward, \n",
    "            },\n",
    "            ignore_index=True\n",
    "        )\n",
    "steps_stats_df.to_csv(\"{dir}/steps_stats.csv\".format(dir=summaries_dir), index=False)\n",
    "\n",
    "\n",
    "episodes_stats_df = pd.DataFrame()\n",
    "ep_count = 0\n",
    "for i, trial_stats in enumerate(stats):\n",
    "    all_rewards = trial_stats['acc_rewards_history']\n",
    "    all_ep_lengths = trial_stats['max_step_history']\n",
    "    all_best_rewards = trial_stats['best_reward_history']\n",
    "    for ep, reward_length in enumerate(zip(all_rewards, all_ep_lengths, all_best_rewards)):\n",
    "        ep_count += 1\n",
    "        episodes_stats_df = episodes_stats_df.append(\n",
    "            {\n",
    "                \"dataset\": config['metadataset']['DatasetID'],\n",
    "                \"trial\": i+1,\n",
    "                \"step\": ep+1,\n",
    "                \"acc_step\": ep_count,\n",
    "                \"acc_reward\": reward_length[0],\n",
    "                \"ep_length\": reward_length[1],\n",
    "                \"best_reward\": reward_length[2],\n",
    "            },\n",
    "            ignore_index=True\n",
    "        )\n",
    "episodes_stats_df.to_csv(\"{dir}/episodes_stats.csv\".format(dir=summaries_dir), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "best_architecture_dbexp.name": "744",
     "best_architecture_dbexp['accuracy']": "0.4738387763500214",
     "best_architecture_dbexp['dataset-nethash']": "traffic_sign-b942e6dcd9d1b73fa5a29d8c6e60ac37",
     "best_architecture_dbexp['density']": "0.0",
     "best_architecture_dbexp['flops']": "0.0",
     "best_architecture_dbexp['is_valid']": "True",
     "best_architecture_dbexp['running_time']": "17",
     "best_global_architecture": "b942e6dcd9d1b73fa5a29d8c6e60ac37",
     "best_global_reward": "47.383877635002136",
     "for layer in best_architecture_dbexp['netstring'].split(\"\\n\"):  print(layer)": "[[0 0 0 0 0]\n [0 0 0 0 0]\n [1 3 3 0 0]\n [2 3 1 1 0]\n [3 1 1 2 0]\n [4 1 1 3 0]\n [5 1 3 4 0]\n [6 1 3 5 0]\n [7 1 5 6 0]\n [8 1 5 7 0]]",
     "len(stats)": "5",
     "len(unique_architectures)": "1041",
     "total_n_episodes": "246"
    }
   },
   "source": [
    "### Global statistics for experiment\n",
    "\n",
    "- **True number of trials:** {{len(stats)}}\n",
    "- **Total number of episodes:** {{total_n_episodes}}\n",
    "- **Number of unique architectures:** {{len(unique_architectures)}}\n",
    "- **Best architecture in experiment:** {{best_global_architecture}}\n",
    "- **Best reward in experiment:** {{best_global_reward}}\n",
    "\n",
    "#### The best architecture\n",
    "\n",
    "```{{for layer in best_architecture_dbexp['netstring'].split(\"\\n\"):  print(layer)}}```\n",
    "\n",
    "\n",
    "**Main information**\n",
    "\n",
    "- **ID:** {{best_architecture_dbexp['dataset-nethash']}}\n",
    "- **Index in DB:** {{best_architecture_dbexp.name}}\n",
    "- **Is valid?** {{best_architecture_dbexp['is_valid']}}\n",
    "- **Accuracy:** {{best_architecture_dbexp['accuracy']}}\n",
    "- **Training time (in sec):** {{best_architecture_dbexp['running_time']}}\n",
    "- **Density:** {{best_architecture_dbexp['density']}}\n",
    "- **FLOPs:** {{best_architecture_dbexp['flops']}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the learning curves of the RL policy and value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:21:26.121846Z",
     "start_time": "2019-07-18T12:21:26.077700Z"
    }
   },
   "outputs": [],
   "source": [
    "progress_df = None\n",
    "for i, openai_dir in enumerate(openai_dirs):\n",
    "    try:\n",
    "        progress_log = \"{dir}/progress.csv\".format(dir=openai_dir)\n",
    "        df_aux = pd.read_csv(progress_log)\n",
    "        if progress_df is None:\n",
    "            progress_df = df_aux.copy()\n",
    "        else:\n",
    "            progress_df = progress_df.append(df_aux)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Could not read the episode_logs in {}\".format(openai_dir))\n",
    "        pass\n",
    "\n",
    "import math\n",
    "\n",
    "tsteps_trial = int(float(config['bash']['NumTimesteps']))\n",
    "factor = 240\n",
    "helpers = np.resize([0,1], progress_df.shape[0])\n",
    "increases = np.array([[tsteps_trial*x, tsteps_trial*x] for x in range(math.ceil(progress_df.shape[0]/2))]).flatten()\n",
    "updates_list = [factor*h + 10 + i for x, h, i in zip(range(progress_df.shape[0]), helpers, increases) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T12:21:26.138364Z",
     "start_time": "2019-07-18T12:21:26.123521Z"
    }
   },
   "outputs": [],
   "source": [
    "res_progress_df = progress_df.copy()\n",
    "res_progress_df.drop(['fps', 'nupdates', 'total_timesteps', 'total_time', 'task'], axis=1, inplace=True, errors='ignore')\n",
    "res_progress_df['total_timesteps'] = updates_list\n",
    "res_progress_df['dataset'] = config['metadataset']['DatasetID']\n",
    "res_progress_df.to_csv(\"{dir}/progress.csv\".format(dir=summaries_dir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
